\section*{Abstract}
\label{sec:Abstract}
\acresetall

This master thesis contributes to the domain of autonomous driving and \ac{RL}. Agents are developed to solve a simplified autonomous driving task in simulation. The agent use \ac{CNN} policies that takes raw camera inputs. The policies are trained in an end-to-end manner using \ac{RL}. The driving task is modelled after physical experiments conducted at the Scads.AI research facility.

This thesis builds upon previous work at the Scads.AI by \autocite{maximilian}, and develops an agent that has to solve the same autonomous driving task. The agent from previous work was not able to reliably complete all tracks. Its performance suffered further under changing light conditions, motivating the research goals of this thesis.

An \ac{RL} agent is developed to traverse simulated tracks of varying difficulty and light settings. The agent's policy consists of a \ac{CNN} that is trained end-to-end using \ac{RL}. The inputs to the \ac{NN} are camera images from the perspective of the agent.
The thesis investigates different training approaches to develop a powerful agent, such as the reward functions and data collection parameters. The most promising policy is used to answer the three research questions.

As a result of the experimentation, a policy is developed that is able to navigate the tracks successfully. The policy has success rates of above 95\% for all investigated tracks and light setting configurations. Further experiments show that the policy can be transfered to a physical robot in theory.
The thesis shows that it is possible to train a \ac{CNN} agent to solve the investigated autonomous driving task using end-to-end \ac{RL}.
