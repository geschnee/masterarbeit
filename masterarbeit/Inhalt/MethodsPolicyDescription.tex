
\section{Policy}
\label{fig:policy_description}

The policy dictates the agent's behaviour. The policy is responsible for selecting actions from observations. The policy is trained using the \ac{PPO} algorithm. The algorithm has proven to be very reliable \textcite{ppo}. The algorithm can be used for our continuous control task.

A neural network is used as for the policy here. The neural network belongs to the class of \acp{CNN}. This architecture was chosen since convolutional neural networks are ideal for processing image data. The convolutional network's architecture follows the specifications from \textcite{human_level_control}. This architecture has been used successfully in comparable reinforcement learning control tasks.

The network takes the output of the observation preprocessing as input. This input is a three dimensional tensor, similar to an image. The network consists of convolutional and fully connected layers. The network produces two outputs, an action distribution and a value function. The action distribution is a probability distribution over the action space.
The value function is a scalar value that estimates the expected return of the current state. The value function is not used during the action inference. The value is only used during the training of the policy network. It is used to compute the advantage function which is required for the loss in \ac{PPO} \textcite{ppo}.

% value or is it the critic? --> it is value


% human_level_control definiert das NatureCNN welches wir nutzen um die features zu extrahieren
% human_level_control hat einfaches Q-learning verwendet, nicht PPO



\subsubsection{Observation Space}

The input space of the neural network is three dimensional. The input is structured like images with $width$, $heigth$ and $channel$ dimensions. The dimensions are determined by the agent's camera image dimensions, preprocessing parameters and the memory mechanism. The input space is a tensor with the following dimensions:

\begin{align*}
    width    & = \frac{agentImageWidth}{downsampling\_factor}  \\
    height   & = \frac{agentImageHeight}{downsampling\_factor} \\
    channels & = frame\_stacking \cdot num\_color\_channels
\end{align*}

The tensor values are integers in the range $[0,255]$. Storing the pixel intensities as integers saves a lot of memory compared to floats.


\subsubsection{Action Space}

The environment's action space is two dimensional, the dimensions are called $leftAcceleration$ and $rightAcceleration$. The values are restricted to the range $[-1,1]$ and dictate the agent movement \ref*{cha:agent_description}.

\subsubsection{Architecture}
\label{sec:network_architecture}

The neural network has an action and a value head. The action head produces the action distribution. The value head produces an estimate of the state's value. 

The action and value head share the first part of the neural network. The shared part is called the feature extractor and consitutes the first four layers. The feature extractor consists of three convolutional layers and one fully connected layer. The first convolutional layer takes the output of the memory buffer as input. The output of the feature extractor's fully connected layer is used by the action and value heads.


\paragraph{Action Head}
\label{sec:action_sampling}

The action head consists of a single fully connected layer with two outputs. The two outputs represent the mean of the action distribution. The action distribution is a Gaussian Distribution. The action distribution can be sampled deterministically or stochastically to obtain an action for the agent. The most likely action is returned in determinsitc sampling. This is equal to the outputs of the action head. In stochastic sampling, the action is sampled from the action distribution.

The sampled actions are clipped to the output space's range $[-1,1]$. This is necessary as the sampling can return a value outside of the range.

\paragraph{Value Head}
The value head consists of a single fully connected layer with one scalar output.

\begin{figure}[!h]
    \centering
    \begin{tikzpicture}[%
            every node/.style={
                    font=\scriptsize,
                    % Better alignment, see https://tex.stackexchange.com/questions/315075
                    text height=1ex,
                    text depth=.25ex,
                }, outer sep=auto
        ]

        \node[draw] (input) at (0, 0) {Input image stack [width, height, channels]};

        \node[draw] (c1) at (0, -1) {Convolutional Layer 1};
        \node[draw] (c2) at (0, -2) {Convolutional Layer 2};
        \node[draw] (c3) at (0, -3) {Convolutional Layer 3};
        \node[draw] (fc1) at (0, -4) {Fully Connected Layer};

        \draw[decorate,decoration={brace,amplitude=5pt}] (3.5,-1) -- (3.5,-4)
        node[anchor=west,midway,right=4pt] {Feature Extractor};

        \node[draw] (fcAction) at (-2, -5.5) {Fully Connected Layer};
        \node[draw] (actionDist) at (-2, -6.5) {Action Distribution};
        \node[draw] (actionOut) at (-2, -7.5) {Action Output};

        \node[draw] (fcValue) at (2, -5.5) {Fully Connected Layer};
        \node[draw] (valueOutput) at (2, -6.5) {Value Output};

        \draw[decorate,decoration={brace,mirror,amplitude=5pt}] (-4,-5.5) -- (-4,-7.5)
        node[anchor=east,midway,left=4pt] {Action Head};

        \draw[decorate,decoration={brace,amplitude=5pt}] (4,-5.5) -- (4,-6.5)
        node[anchor=west,midway,right=4pt] {Value Head};

        \draw[->,thick] (input.south) -- (c1.north);
        \draw[->,thick] (c1.south) -- (c2.north);
        \draw[->,thick] (c2.south) -- (c3.north);
        \draw[->,thick] (c3.south) -- (fc1.north);

        \draw[->,thick] (fc1.south) -- (fcAction.north);
        \draw[->,thick] (fcAction.south) -- (actionDist.north);
        \draw[->,thick] (actionDist.south) -- (actionOut.north);

        \draw[->,thick] (fc1.south) -- (fcValue.north);
        \draw[->,thick] (fcValue.south) -- (valueOutput.north);

    \end{tikzpicture}
    \caption{Neural Network Structure}
    \label{fig:network_structure}
\end{figure}


\subsubsection{Parameters}
The neural network's input dimensions are determined by the agent's camera image dimensions and the observation processing. The network architecture follows the specifications from \textcite{human_level_control}. However the observation space differ from their network. This results in a different number of parameters for the feature extractor's layers.
The parameters and layer dimensions used network are shown in figure \ref{fig:network_architecture}.


% verified in code:
% action and value head share the extractor
% when sampling deterministic, the action is the mean of the distribution
% the output of the action head is the mean of the distribution

% the action head is a single linear layer, there is no activation function applied to the output

% DiagGaussianDistribution
% the log std of the distribution is a learnable parameter
% it is also updated, see policy_loss (the single parameter of size 2 that is added in the graph last)

\begin{figure}
    \begin{center}
        \begin{tabular}{|| c | p{0.25\linewidth} | p{0.4\linewidth} ||}
            \hline
            Component                          & Layer Type            & Layer Specifications                     \\ [0.5ex]
            \hline\hline
            \multirow{4}{*}{Feature Extractor} & Convolutional Layer   & 32 filters, 3 dimensional (10, 8, 8)     \\\cline{2-3}
                                               & Convolutional Layer   & 64 filters, 3 dimensional (32, 4, 4)     \\\cline{2-3}
                                               & Convolutional Layer   & 64 filters, 3 dimensional (64, 3, 3)     \\\cline{2-3}
                                               & Fully connected Layer & 512 output neurons, (512 x 12096) matrix \\
            \hline
            Action Head                        & Fully connected Layer & 2 output neurons, (2 x 512) matrix       \\
            \hline
            Value Head                         & Fully connected Layer & 1 output neuron, (1 x 512) matrix        \\
            \hline
        \end{tabular}
        \begin{tabular}{r@{: }l}
            $agentImageWidth$      & 500  \\
            $agentImageHeight$     & 168  \\
            $downsampling\_factor$ & 2    \\
            $greyscale$            & True \\
            $equalize$             & True \\
            $frame\_stacking$      & 10   \\
        \end{tabular}
    \end{center}
    \caption{Neural network layers and parameters for the best configuration}
    \label{fig:network_architecture}
\end{figure}

