% TODO put a figure her that describes the policy
% image from unity, preprocessing, neural network, apply acceleration for (fixed) time

\section{Policy Description}

\label{fig:policy_description}

The policy dictates what action the agent takes. The policy consists of preprocessing steps, a memory mechanism and a neural network. The policy is applied to images from the agent camera. The resulting actions are then applied to the agent in the Unity environment. 
The preprocessing steps and memory mechanism are considered as part of the policy as they are applied to the input images before the neural network. The preprocessing steps cannot be changed for a trained policy, as they define dimensions and contents of the neural network's inputs.

The agent's camera image has three channels, red, green, and blue. Its dimensions are defined by the config parameters $agentImageWidth$ and $agentImageHeight$. These parameters define the agent's field of view.
The policy receives an image from the agent camera as input. First the image is preprocessed. This changes the image content and dimensions. The preprocessed image is then combined with the memory mechanism to produce the inputs to the policy's neural network. The network then produces an action.

% TODO an image of the entire policy process
% image from agent, prepro, memory, network, action

\subsection{Preprocessing}

The images from the agent camera are preprocessed before they are fed into the neural network. The preprocessing steps are applied to reduce the size of the neural network's input space. They are also applied to reduce the impact of different light settings on the policy's performance.
Three preprocessing steps have been implemented, downsampling, grayscale conversion, and histogram equalization. The preprocessing steps can be enabled and configured in the environment parameter $image\_preprocessing$. Each preprocessing step transforms an image into a new image. This can change the image dimensions and pixel domains. The steps are applied on the previous step's output. The steps are applied in order of downsampling, grayscale conversion, and histogram equalization. The first step takes the image from the agent camera as input. 
The neural network uses the last step's output for inference.

The preprocessing steps are applied to all images from the agent camera. The table \ref{table:preprocessing_steps} shows how the preprocessing steps make images of different light settings more similar. The images in the table were generated using the configurations employed int the training runs.


\newcommand{\unityImg}[1]{\includegraphics[width=1\linewidth]{Bilder/image_printer_images/preprocessingSteps/fixedSpawnPoint_hardBlueFirstLeft_#1_image_from_unity.png}}
\newcommand{\downsampledImg}[1]{\includegraphics[width=1\linewidth]{Bilder/image_printer_images/preprocessingSteps/fixedSpawnPoint_hardBlueFirstLeft_#1_downsampled.png}}
\newcommand{\grayscaleImg}[1]{\includegraphics[width=1\linewidth]{Bilder/image_printer_images/preprocessingSteps/fixedSpawnPoint_hardBlueFirstLeft_#1_grayscale.png}}
\newcommand{\equalizedImg}[1]{\includegraphics[width=1\linewidth]{Bilder/image_printer_images/preprocessingSteps/fixedSpawnPoint_hardBlueFirstLeft_#1_equalized.png}}
\newcommand{\finalImg}[1]{\includegraphics[width=1\linewidth]{Bilder/image_printer_images/preprocessingSteps/fixedSpawnPoint_hardBlueFirstLeft_#1.png}}
\begin{table}
    \begin{center}
        \begin{tabular}{|| p{0.15\linewidth} || p{0.25\linewidth} | p{0.25\linewidth} | p{0.25\linewidth} ||}
            \hline
            light Setting     & Bright                             & Standard                             & Dark                             \\ [0.5ex]
            \hline\hline
            Agent Camera Image from Unity  & \makecell{\unityImg{bright}}       & \makecell{\unityImg{standard}}       & \makecell{\unityImg{dark}}       \\
            \hline
            Downsampled & \makecell{\downsampledImg{bright}} & \makecell{\downsampledImg{standard}} & \makecell{\downsampledImg{dark}} \\
            \hline
            Grayscale & \makecell{\grayscaleImg{bright}}   & \makecell{\grayscaleImg{standard}}   & \makecell{\grayscaleImg{dark}}   \\
            \hline
            Equalized & \makecell{\equalizedImg{bright}}   & \makecell{\equalizedImg{standard}}   & \makecell{\equalizedImg{dark}}   \\
            \hline
            Final Input Image & \makecell{\finalImg{bright}}       & \makecell{\finalImg{standard}}       & \makecell{\finalImg{dark}}       \\
            \hline
        \end{tabular}
    \end{center}
    \caption{Preprocessing steps applied to images from the agent camera at the different light settings. The steps are applied in order from top to bottom.}
    \label{table:preprocessing_steps}
\end{table}

\subsubsection*{Benefits of reducing the input space size}

The reduction of input space size brings a variety of benefits. Some benefits are execution driven, like the reduction of the neural network's inference time. The neural network can make decisions quicker if it has to process fewer inputs. The reduction of the input space size also reduces the amount of data that has to be stored in memory. This is especially important during the training phase since many observations have to be stored in the rollout buffer.

The reduction of the input space size also reduces the number of parameters the neural network has to learn. This can lead to a more robust policy. Networks with smaller input spaces and less parameters are less prone to overfitting. The policy can generalize better to unseen situations. 

% what datatype is used for the images? uint8? float32?
% there was a problem before with some datatype requiring more space than others
% change of datatype during preprocessing?

\subsubsection*{Benefits of reducing the impact of different light settings}

The policy has to be able to complete the different tracks for three different light settings. The policy is not provided with information about what light setting is active for the current episode. This means that the policy has to learn to produce correct actions for images of all three light settings. If images of the light settings look very different, the policy has to learn to the light settings as well as what action to take. 
The preprocessing steps are applied to make images of different light settings more similar. The neural network is relieved of learning the different light settings. This can make learning easier and faster. 
The preprocessing steps can also make the policy generalize better to unseen light settings. The policy can be trained on a single light setting and achieve good results for the other light setttings \ref{cha:experiment_mixed_training}. 



\subsubsection{Downsampling}

The downsampling step changes the resolution and dimensions of the image. The step is configured with the $downsampling\_factor$ parameter. The downsampling factor is a positive integer and determines how much the image is downscaled. A $downsampling\_factor$ of one results in no downsampling. The width and height dimensions of the input image are divided by $downsampling\_factor$ to produce the new image dimensions.
The downsampling process divides the input image in a grid. The grid cells are $downsampling\_factor$ pixels wide and high. The pixel values of the new image are calculated by averaging the pixel values of the grid cells. The new image has a lower resolution than the input image.
Downsampling reduces the size of the input space substantially.


% TODO test with downsampling factor 3 (just to see if the python code works)

\subsubsection{Grayscale}

The grayscale step converts the image to grayscale. The step can be enabled or disabled with the $grayscale$ parameter. The agent's camera image has three channels, red, green, and blue. The grayscale step changes the amount of channels and returns an image with a single grayscale channel. The grayscale image has the same width and height dimensions as the input image. The grayscaling reduces the input space size by a third.
The pixel values of the grayscale image are calculated as the weighted sum of intensities of the red, green, and blue channels. The weights are determined by the human eye's perception of the different colors. The grayscale value is computed as $Y = 0.2125 * R + 0.7154 * G + 0.0721 * B$.

The conversion to grayscale removes color information from the image. The alternating goal colors red and blue are no longer distinguishible. The advantage of grayscale images is that the policy's neural network does not have to learn the three dimensional colorspace of RGB images.



\subsubsection{Histogram Equalization}
\label{sec:histogram_equalization}

The histogram equalization step increases the contrast of the image. The step can be enabled or disabled with the $equalize\_histogram$ parameter. The histogram equalization step requires a grayscale image as input. The step changes the pixel values of the image. The step does not change the input space size.
The histogram equalization step changes the pixel values of the image. The histogram of the pixel intensities are made more uniform. First the cumulative histogram of the pixel intensities is calculated. The pixel values are then mapped to new values by using the cumulative histogram. The pixel values are distributed more evenly over the pixel value domain \ref{fig:histogram_equalization}.

The histogram equalization step can make images of different light settings more similar. The step also increases the contrast in the images. This can make it easier for the neural network to detect the objects.

\begin{figure}
    \centering
    \subfigure[Original Image]{\includegraphics[width=0.3\textwidth]{Bilder/image_printer_images/histogram/original_image.png}}
    \subfigure[Equalized Image Image]{\includegraphics[width=0.3\textwidth]{Bilder/image_printer_images/histogram/equalized_image.png}}\\
    \subfigure[Original Image Histogram]{\includegraphics[width=0.3\textwidth]{Bilder/image_printer_images/histogram/original_histogram.png}}
    \subfigure[Equalized Image Histogram]{\includegraphics[width=0.3\textwidth]{Bilder/image_printer_images/histogram/equalized_histogram.png}}\\
    \caption{Histogram equalization of a grayscale image from standard light setting}
    \label{fig:histogram_equalization}
\end{figure}


\subsection{Memory Mechanism}

Memory mechanisms are a common approach to enhancing a reinforcement learning agent. Memory mechanisms can be implemented in many different ways. Our memory mechanism uses frame stacking, similar to \autocite{maximilian} and \autocite{atari}. The memory is configured with the $frame_stacking$ parameter. The memory is a simple first-in-first-out buffer that stores the last $frame_stacking$ images. The memory is updated by inserting the new image and removing the oldest image. The inserted images are the outputs of the preprocessing steps.
The images from the memory buffer are concatenated along the channel axis to produce the neural network input. This neural network input is essentially an image with many channels.
The memory buffer is reset at the start of every episode. The reset fills the entire buffer with zeros. The zeros are used as a placeholder. The first-in-first-out mechanism removes the zeros over the first $frame\_stacking$ timesteps.

The memory mechanism enables the policy to use information from previous time steps. The policy can use this information to detect objects that are not visible in the current image. Depending on the agent's position and orientation, the next goal might only be partially visible or not visible at all. The past images can help the policy reason about the next goal's position and how to continue.

% the memory also acts as a regularizer? more input data that can be used to learn the task? the images are highly correlated, it pobably would not need the newest image to decide on the action


\newcommand{\includePreprocessedImage}[1]{\includegraphics[width=0.15\textwidth]{Bilder/image_printer_images/memory_mechanism/preprocessed_image_step_#1.png}}
\newcommand\timestepT{5}
\newcommand\timestepTminusOne{4}
\newcommand\timestepTminusTwo{3}
\newcommand\timestepTminusThree{2}
\newcommand\timestepTminusFour{1}
\newcommand\imagesOffsetY{0}
\newcommand\inOutImageHeight{0.75}
\newcommand\bufferXOffset{-2}
\newcommand\bufferWidth{7}


\usetikzlibrary{fit}

\begin{figure}[!h]
\centering
\begin{tikzpicture}[%
    every node/.style={
        font=\scriptsize,
        % Better alignment, see https://tex.stackexchange.com/questions/315075
        text height=1ex,
        text depth=.25ex,
    },
]

\node[inner sep=0pt] (newImg) at (-4,\inOutImageHeight)
    {\includePreprocessedImage{\timestepT}};
\node[below] at (newImg.south) {New preprocessed image $t$};


\node[inner sep=0pt] (step3) at (\bufferXOffset + 4.5,\imagesOffsetY + 1.5)
    {\includePreprocessedImage{\timestepTminusThree}};
\node[below] at (step3.east) {image $t - 3$};

\node[inner sep=0pt] (step2) at (\bufferXOffset + 3.5,\imagesOffsetY + 1)
    {\includePreprocessedImage{\timestepTminusTwo}};
\node[below] at (step2.east) {image $t - 2$};

\node[inner sep=0pt] (step1) at (\bufferXOffset + 2.5,\imagesOffsetY + 0.5)
    {\includePreprocessedImage{\timestepTminusOne}};
\node[below] at (step1.east) {image $t - 1$};

\node[inner sep=0pt] (step0) at (\bufferXOffset + 1.5,\imagesOffsetY)
    {\includePreprocessedImage{\timestepT}};
\node[below] at (step0.south) {new image $t$};

\node[fit={(\bufferXOffset,-0.55) (\bufferXOffset + \bufferWidth,2.5)}, inner sep=0pt, draw=blue, thick] (buffer) {};
\node[below] (buffertext1) at (buffer.south) {Memory Buffer stack for timestep $t$};
\node[below] (buffertext2) at (buffertext1.south) {$frame\_stacking = 4$};
\node[below] (buffertext3) at (buffertext2.south) {Output dimensions: $[width, height, frame\_stacking]$};


\node[inner sep=0pt] (outImg) at (7,\inOutImageHeight)
    {\includePreprocessedImage{\timestepTminusFour}};
\node[below] at (outImg.south) {Removed image $t - 4$};

\draw[->,thick] (\bufferXOffset - 0.75, 1) -- (\bufferXOffset, 1);
\draw[->,thick] (\bufferXOffset + \bufferWidth, 1) -- (\bufferXOffset + \bufferWidth + 0.75, 1);


\end{tikzpicture}
\caption{Memory Mechanism}
\label{fig:memory_mechanism}
\end{figure}


\subsection{Neural Network}

The neural network is the core of the policy. It is responsible for producing the actions from the image observations. The neural network belongs to the class of convolutional neural networks. This architecture was chosen since convolutional neural networks are ideal for processing image data. The convolutional network's architecture follows the specifications from \autocite{human_level_control}. This architecture has been used successfully in comparable reinforcement learning problems.

The network takes the output of the memory mechanism as input. This input is a three dimensional tensor, similar to an image. The network consists of convolutional and fully connected layers. The network produces two outputs, an action distribution and a value function. The action distribution is a probability distribution over the action space. 
The value function is a scalar value that estimates the expected return of the current state. The value function is not used during the action inference. The value is only used during the training of the policy network. It is used to compute the advantage function which is required for the loss \autocite{ppo}.

% value or is it the critic? --> it is value

% TODO welches paper hat die architektur beschrieben? nature paper?
% human_level_conrtol definiert das NatureCNN welches wir nutzen um die features zu extrahieren
% human_level_control hat einfaches Q-learning verwendet, nicht PPO

% TODO remove the neural network head configs from config files?

\subsubsection{Input Space}

The input space of the neural network is three dimensional. The input is structured like images with $width$, $heigth$ and $channel$ dimensions. The dimensions are determined by the agent's camera image dimensions, preprocessing parameters and the memory mechanism. The input space is a tensor with the following dimensions:

\begin{align*}
    width &= \frac{agentImageWidth}{downsampling\_factor} \\   
    height &= \frac{agentImageHeight}{downsampling\_factor} \\     
    channels &= frame\_stacking \cdot num\_color\_channels
\end{align*}

The tensor values are integers in the range $[0,255]$. Storing the pixel intensities as integers saves a lot of memory compared to floats.


\subsubsection{Action Output Space}

The environment's action space is two dimensional, the dimensions are called $leftAcceleration$ and $rightAcceleration$. The values are restricted to the range $[-1,1]$ and dictate the agent movement \ref*{cha:agent_description}.

\subsubsection{Architecture}
\label{sec:network_architecture}

The neural network has an action and a value head. The action head produces the action distribution. The value head produces an estimate of the state's value. The action and value head share a part of the neural network. The shared part is called the feature extractor and consitutes the first four layers. The feature extractor consists of three convolutional layers and one fully connected layer. The first convolutional layer takes the output of the memory buffer as input. The output of the feature extractor's fully connected layer is used by the action and value heads.

The action head consists of a single fully connected layer with two outputs. The two outputs represent the mean of the action distribution. The action distribution is a Gaussian Distribution. The action distribution can be sampled deterministically or stochastically to obtain an action for the agent. The most likely action is returned in determinsitc sampling. This is equal to the outputs of the action head. In stochastic sampling, the action is sampled from the action distribution.
The sampled actions are clipped to the output space's range $[-1,1]$. This is necessary as the sampling can return a value outside of the range.

The value head consists of a single fully connected layer with one output.

\begin{figure}[!h]
    \centering
    \begin{tikzpicture}[%
        every node/.style={
            font=\scriptsize,
            % Better alignment, see https://tex.stackexchange.com/questions/315075
            text height=1ex,
            text depth=.25ex,
        }, outer sep=auto
    ]
    
    \node[draw] (input) at (0, 0) {Input image stack [width, height, channels]};
    
    \node[draw] (c1) at (0, -1) {Convolutional Layer 1};
    \node[draw] (c2) at (0, -2) {Convolutional Layer 2};
    \node[draw] (c3) at (0, -3) {Convolutional Layer 3};
    \node[draw] (fc1) at (0, -4) {Fully Connected Layer};
    
    \draw[decorate,decoration={brace,amplitude=5pt}] (3.5,-1) -- (3.5,-4)
        node[anchor=west,midway,right=4pt] {Feature Extractor};
    
    \node[draw] (fcAction) at (-2, -5.5) {Fully Connected Layer};
    \node[draw] (actionDist) at (-2, -6.5) {Action Distribution};
    \node[draw] (actionOut) at (-2, -7.5) {Action Output};
    
    \node[draw] (fcValue) at (2, -5.5) {Fully Connected Layer};
    \node[draw] (valueOutput) at (2, -6.5) {Value Output};
    
    \draw[decorate,decoration={brace,mirror,amplitude=5pt}] (-4,-5.5) -- (-4,-7.5)
        node[anchor=east,midway,left=4pt] {Action Head};
    
    \draw[decorate,decoration={brace,amplitude=5pt}] (4,-5.5) -- (4,-6.5)
        node[anchor=west,midway,right=4pt] {Value Head};
    
    \draw[->,thick] (input.south) -- (c1.north);
    \draw[->,thick] (c1.south) -- (c2.north);
    \draw[->,thick] (c2.south) -- (c3.north);
    \draw[->,thick] (c3.south) -- (fc1.north);
    
    \draw[->,thick] (fc1.south) -- (fcAction.north);
    \draw[->,thick] (fcAction.south) -- (actionDist.north);
    \draw[->,thick] (actionDist.south) -- (actionOut.north);
    
    \draw[->,thick] (fc1.south) -- (fcValue.north);
    \draw[->,thick] (fcValue.south) -- (valueOutput.north);
   
    \end{tikzpicture}
\caption{Neural Network Structure}
\label{fig:network_structure}
\end{figure}

The neural network's input dimensions are determined by the agent's camera image dimensions, preprocessing parameters and the memory mechanism. The network architecture follows the specifications from \autocite{human_level_control}. However the input dimensions differ from the original network. This results in a different number of parameters for the feature extractor's layers.
The parameters and layer dimensions for the most successful network configuration are shown in figure \ref{fig:network_architecture}.


% verified in code:
% action and value head share the extractor
% when sampling deterministic, the action is the mean of the distribution
% the output of the action head is the mean of the distribution

% the action head is a single linear layer, there is no activation function applied to the output

% DiagGaussianDistribution
% the log std of the distribution is a learnable parameter
% it is also updated, see policy_loss (the single parameter of size 2 that is added in the graph last)

\begin{figure}
    \begin{center}
    \begin{tabular}{|| c | p{0.25\linewidth} | p{0.4\linewidth} ||} 
        \hline
        Component & Layer Type & Layer Specifications \\ [0.5ex] 
        \hline\hline
        \multirow{4}{*}{Feature Extractor} & Convolutional Layer & 32 filters, 3 dimensional (10, 8, 8) \\\cline{2-3}
        & Convolutional Layer & 64 filters, 3 dimensional (32, 4, 4) \\\cline{2-3}
        & Convolutional Layer & 64 filters, 3 dimensional (64, 3, 3) \\\cline{2-3}
        & Fully connected Layer & 512 output neurons, (512 x 12096) matrix \\
        \hline
        Action Head & Fully connected Layer & 2 output neurons, (2 x 512) matrix \\
        \hline
        Value Head & Fully connected Layer & 1 output neuron, (1 x 512) matrix \\
        \hline
    \end{tabular}
    \begin{tabular}{r@{: }l}
        $agentImageWidth$ & 500 \\
        $agentImageHeight$ & 168 \\
        $downsampling\_factor$ & 2 \\
        $greyscale$ & True \\
        $equalize$ & True \\
        $frame\_stacking$ & 10 \\
    \end{tabular}
    \end{center}
    \caption{Neural network layers and parameters for the best configuration}
    \label{fig:network_architecture}
\end{figure}

