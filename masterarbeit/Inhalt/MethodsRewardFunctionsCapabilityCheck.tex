

\section{Reward functions capability check}

Previous sections introduced the composite reward function. The composite reward function consists of a weighted sum of individual reward functions. The individual reward functions are designed to encourage the agent to learn the desired behaviour. The goal is to achieve an agent that completes the parcour without collisions, this is encapsulated in the event reward function. However the event reward function is a very sparse signal, which makes it hard for the agent to learn from. The other individual reward functions are designed to be dense reward functions, they give rewards in every episode step.

It is important to find appropriate weights of the individual reward functions for the composite reward function. We are conducting experiments to analyse the usefullness of the individual reward functions. First we analyse if the agent is capable of learning the behaviour encouraged by the reward function.
This is done by training the agent with only one reward function at a time. The reward function's coefficient is set to one. The coefficients of the other reward functions are set to zero. The agent is trained on easy tracks with a Random spawnOrientation and standard lightSetting to reduce the difficulty of learning the encouraged behaviour.
% todo link the configs?
% ppo_rewardFunction_capability_check_orientationReward.yaml


The experiment results are shown in \ref{table:reward_functions_behaviour}. The agent is capable of learning the behaviour encouraged by the distanceReward and velocityReward functions. However the agent is not capable of learning the behaviour encouraged by the eventReward and orientationReward functions. 
...TODO more text after rerunning the experiments

% TODO nochmal ausf√ºhren und dokumentieren oder ist das schon in Excel?

\begin{table}
\caption{Agent capability check for individual reward functions.}
\begin{center}
\begin{tabular}{|| c | p{0.3\textwidth} | p{0.3\textwidth} | p{0.1\textwidth} ||} 
    \hline
    function name & encouraged behaviour & learned behaviour  & expected behaviour learned? \\ [0.5ex] 
    \hline\hline
    eventReward &  agent drives through the parcour without collisions & agent turns on the spot continuously & no \\ 
    \hline
    distanceReward & agent drives towards the next goal & agent drives towards the next goal & yes \\
    \hline
    orientationReward & agent turns towards closest goal & agent turns around on the spot continuously & no \\
    \hline
    velocityReward  & full speed ahead (no turning) & full speed ahead (no turning) & yes \\
    \hline
\end{tabular}
\end{center}
\label{table:reward_functions_behaviour}
\end{table}